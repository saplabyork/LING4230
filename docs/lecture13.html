<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Consonant perception</title>

<script src="site_libs/header-attrs-2.17/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/paper.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link rel="shortcut icon" href="images/logo.jpeg">

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>









<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">LING2200</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="lecture1.html">Lecture 1</a>
</li>
<li>
  <a href="lecture2.html">Lecture 2</a>
</li>
<li>
  <a href="lecture3.html">Lecture 3</a>
</li>
<li>
  <a href="lecture4.html">Lecture 4</a>
</li>
<li>
  <a href="lecture5.html">Lecture 5</a>
</li>
<li>
  <a href="lecture6.html">Lecture 6</a>
</li>
<li>
  <a href="lecture7.html">Lecture 7</a>
</li>
<li>
  <a href="MTreview.html">MT &amp; practice</a>
</li>
<li>
  <a href="lecture8.html">Lecture 8</a>
</li>
<li>
  <a href="lecture9.html">Lecture 9</a>
</li>
<li>
  <a href="lecture10.html">Lecture 10</a>
</li>
<li>
  <a href="lecture11.html">Lecture 11</a>
</li>
<li>
  <a href="lecture12.html">Lecture 12</a>
</li>
<li>
  <a href="lecture13.html">Lecture 13</a>
</li>
<li>
  <a href="lecture14.html">Lecture 14</a>
</li>
<li>
  <a href="lecture15.html">Lecture 15</a>
</li>
<li>
  <a href="lecture16.html">Lecture 16</a>
</li>
<li>
  <a href="final_review.html">Final test review</a>
</li>
<li>
  <a href="lecture17.html">Lecture 17</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Consonant perception</h1>

</div>


<style type="text/css">
  body{
  font-size: 12pt;
}
</style>
<hr />
<p>We’ve spent some time discussing phonation and filtering which
results in vowel (or vocalic) sounds. We’ve also briefly discussed the
idea that perception is not a one-to-one mapping of acoustics to a
representation in your brain. Today we switch gears, slightly, and
introduce consonant perception. For the most part, consonants are
produced with some sort of occlusion in the vocal tract, a constricting
of the walls of the mouth or the contact of the tongue with the superior
surface of the oral cavity.</p>
<hr />
<div id="categorical-perception" class="section level1">
<h1>Categorical perception</h1>
<p>Categorical perception refers to a general phenomenon whereby humans
(and other animals) categorize objects with similar features–but for our
purposes it really is the study of how our built-up categories can be
imposed on external features. Our notion of “chair” is such that any
object with four-legs and is “sittable” might fit into that category.
Crucially, my category of chair might be different from yours. We can
extend this general phenomenon to the speech domain.</p>
<p>In general, the vowel space is thought to be perceived more or less
<em>continuously</em>. There is some intuitive sense to this, as I can
seamlessly transition a production of “aah” to “ooo” and you would be
hard pressed to identify when it changes category. That is, there is no
clear boundary between the productions, but rather the acoustic shape
shifting gives rise to a continuous perception.</p>
<p>Contrast that with consonants. If a series of consonants are
presented to a listener, with each consonant differing only slightly
from the other in one small respect along some acoustic dimension, there
would be a point in the presentation where the listener’s perception
goes from one phoneme to another. On either sides of this crossover
consonants are perceived as being the same.</p>
<p align="center">
<img src="images/ideal_crossover.jpeg" width="50%" height="50%">
</p>
<p>The image above is called a <strong>identification function</strong>.
A stimulus (from the x-axis) is played to the listener and the listener
is asked to identify the sound. The x-axis consists of a series of sound
stimuli, at the left end is definitively a /ba/ and at the right end
definitively a /da/. In between are 8 stimuli that are more or less /ba/
or /da/ like. If you were to hear all 10 stimuli they would slowly
change from “ba” to “da”. It’s important to note that each stimulus in
the continuum differs by exactly the same “amount.” When the stimuli are
played to listeners, however, they treat the left 4 stimuli as /ba/ 100%
of the time(!) even though each one is actually slightly different. So
the listener’s brain collapses the differences and treats them all as
“ba”. BUT, when they get stimuli 5 and 6, they are 50% in their
identification.</p>
<p>The image above is an <em>idealized</em> identification curve and we
don’t really know what the acoustic dimension being varied along the
x-axis is. A typical categorical perception task with consonants
exploits a timing relationship between the release of the oral occlusion
and the onset of vocal fold oscillation of the following vowel.</p>
</div>
<div id="voice-onset-time" class="section level1">
<h1>Voice onset time</h1>
<p>To begin with, the <em>sound</em> of a consonant is extremely brief.
It’s the release of the occlusion in the vocal tract, giving rise to a
noisy burst of energy, typically called a <strong>burst</strong>. We can
understand a lot about the consonant (whether it is a /t/ or a /d/; /p/
or /b/, etc.) from the how the burst is timed with respect to the
beginning of the following vowel. This aspect of consonant acoustics,
especially for consonants that are followed by a vowel, is called
<strong>voice onset time</strong> or VOT.</p>
<p>Imagine the articulatory and aerodynamic processes involved in the
production of an oral consonant follow by a vowel, like “pa”:</p>
<ol style="list-style-type: decimal">
<li>The articulator makes contact with the place of articulation,
creating a tight seal</li>
<li>Air pressure builds up behind the constriction</li>
<li>Constriction is released</li>
<li>Voicing of the vowel begins</li>
</ol>
<p>The synchronization of 3. and 4. characterizes VOT.</p>
<p align="center">
<img src="images/vot_schematic.png" width="50%" height="50%"><img src="images/vot_real.png" width="50%" height="50%">
</p>
<p>In the schematic image on the left, there are three different “types”
of VOTs shown.</p>
<ol style="list-style-type: decimal">
<li>Zero VOT: the release of the constriction is timed perfectly with
the onset of vocal fold oscillation (similar to “voiced” consonants in
North American English, “ba”, “da”, “ga”)</li>
<li>Positive VOT: there is a brief silence or time gap between the
release of the constriction and the onset of phonation (like
syllable-initial “voiceless” consonants in English, “pa”,“ta”,
“ka”)</li>
<li>Negative VOT: where phonation begins before the release of the
consonants. We do this in connected English speech usually for voiced
stop consonants, but it also happens in place of zero VOT for some
speakers of English.</li>
</ol>
<p>Here is a continuum of <a href="sounds/chain.wav">VOT</a> doing from
“da” to “ta”. The individual sounds from the continuum are found <a
href="vot_continuum.html">here</a>.</p>
<p>Below are the waveforms for the synthetic VOT continuum. Though it’s
hard to see here, notice that the initial noise burst slowly disappears
as you move from left to right. Remember, the vowel-consonant (of the
CVC sequence) remain the same in every token, just the VOT changes.</p>
<p align="center">
<img src="images/d_t_continuum.png" width="100%" height="100%">
</p>
<p>When we did this identification exercise in class we got a pretty
good approximation to the idealized categorical perception curve above.
What this means is that listeners cannot distinguish between tokens on
either side of a <em>crossover</em>, generally in the middle area of the
continuum. That is, on either side of the crossover is a “category”, in
this case, either a “d” or a “t.”</p>
</div>
<div id="f2-transition" class="section level1">
<h1>F2 transition</h1>
<p>Categorical perception in speech occurs with acoustic cues other than
VOT too. For example, the place of articulation of a consonant is cued
by the frequency of F2 at the beginning of a vowel in a CV sequence.
This “F2 transition” tells us whether we’re hearing a bilabial,
alveolar, or velar stop.</p>
<p>Below is an image of synthetic CV stimuli that show the relationship
between the onset of F2 in the vowel and percept. Notice how the F2
transition is modulated by the identity of the vowel. In general, for
bilabials the F2 onset “points” down, while for velars, it points up.
For alveolars it’s more tightly linked to the vowel identity.</p>
<p align="center">
<img src="images/formant-transitions.png" width="70%" height="70%">
</p>
<p>You’ll also notice that it’s not only the onset frequency of F2 that
varies, but also the duration of the transition before the vowel’s
steady state.</p>
</div>
<div id="trading-relationships" class="section level1">
<h1>Trading relationships</h1>
<p>Consonants (and to some extent vowels) are not defined (perceptually)
purely by singular acoustic cues. For example, something like voicing is
not <em>just</em> VOT. Rather, there are multiple acoustic cues that
contribute to the perception of some phonological feature or
characteristic. Continuuing with the voicing feature (distinguishing
p/b, t/d, k/g) there are other cues that trigger voicing for the
listener.</p>
<div id="f1-cutback-pitch-perturbation" class="section level2">
<h2>F1 cutback, Pitch perturbation</h2>
<ol style="list-style-type: decimal">
<li>F1 cutback: When a stop is released there is a (sometimes) brief
moment before the onset of the following vowel (in a CV sequence). This
moment (called VOT) is characterized by the coupling of the trachea with
the oro-pharyngeal cavities. When these tubes are coupled there is a
low-frequency <em>anti-resonance</em> (as well as the more typical
frication associated with VOT) such that there is no energy in the F1
region. This is called <strong>F1 cutback</strong>, and can extend into
the vowel. That is, the higher formants of the vowel can start before we
see energy in F1. When F1 does appear, it is higher in voiceless
consonants than it is in voiced consonants.</li>
</ol>
<p>So when F1 is delayed it is naturally high <span
class="math inline">\(\rightarrow\)</span> voiceless percept; F1 is not
delayed, it is low <span class="math inline">\(\rightarrow\)</span>
voiced percept.</p>
<ol start="2" style="list-style-type: decimal">
<li>Pitch perturbation: It’s called “pitch” perturbation but it refers
to the physical phenomenon of the F0 being lower in voiced CVs than in
voiceless CVs. It is a very subtle, but reliable difference that
reflects the fact that when there is a voiceless stop, after release of
the consonant there is enough time for intraoral pressure to rapidly
decrease, thereby allowing air to more rapidly across the vocal folds
resulting in momentary high F0; whereas with voiced stops the pressue in
the oral cavity is relatively high so air flow across the vocal folds is
momentarily low, resulting in low F0.</li>
</ol>
<p>Listeners are sensitive to the relationship between High F0/Voiceless
consonant, Low F0/Voiced consonant.</p>
<p>Together with VOT, F1 cutback and Pitch Perturbation form a trading
relationship for the perception of voicing in CVs. The listener doesn’t
treat all of these cues equally, however. There’s evidence that listners
<em>weight</em> VOT greater than F1 cutback or Pitch Perturbation, that
is, it a more <em>salient</em> cue.</p>
<p>So, in the absence of the more heavily weighted cue, the other cue(s)
may allow the listener to recover the percept.</p>
</div>
</div>
<div id="coarticulation" class="section level1">
<h1>Coarticulation</h1>
<p>We’ve talked about coarticulation before. It is the phenomenon
whereby adjacent sounds influence each other when articulations are
initiated before the preceding articulation is complete. The reasons for
this might include efficiency while maximizing information transmission.
Perceptually, the listener must unpack coarticulated utteracnces to
recover the intended phonemes. It turns out that listeners are very good
at this, that is, they know what the accoustic consequences of
coarticulation are.</p>
<p>Acoustic elements of preceding and following sounds are incorporated
into target sounds as a result of coarticulation. For example, in the
word “soo”, lip rounding from /u/ is present during the production of
/s/. In “see”, however, the lips are spreading during /s/ in
anticipation of /i/. The resulting acoustics are such that the high
frequency bandwidth of /s/ in “soo” is wider than the /s/ in “see.”</p>
<p align="center">
<img src="images/sisu.png" width="70%" height="70%">
</p>
<p>There are continuously shifting acoustic features that interact with
and affect adjacent features. Listeners integrate acoustic information
that is spread over many phonetic segments in order to make a judgement
about a particular phone’s identity.</p>
</div>
<div id="perception-of-consonants" class="section level1">
<h1>Perception of consonants</h1>
<div id="liquids" class="section level2">
<h2>Liquids</h2>
<p>Liquids (/l/ and /r/) are similar to diphthongs (consisting of a
movement to two positions) and recognized on the basis of their formant
transition or movement. Unlike diphthongs, the transitions for liquids
are much faster. F3 is also important for differentiating liquids, being
lower in /r/ than /l/. Below is “la” followed by “ra”. Notice in the
liquid initial portion that F3 is basically overlapping with F2 in
“ra”.</p>
<p align="center">
<img src="images/rala.png" width="70%" height="70%">
</p>
</div>
<div id="glides" class="section level2">
<h2>Glides</h2>
<p>The glides /j/ and /w/ are characterized by transitions that are
shorter than in diphthongs. When the transition duration is shorter than
40-60ms, listeners hear a stop, but when it is between 60-150ms, they
judge the sound to be a a glide. The image below is /ja/ followed by
/wa/.</p>
<p align="center">
<img src="images/jawa.png" width="70%" height="70%">
</p>
</div>
<div id="nasals" class="section level2">
<h2>Nasals</h2>
<p>Nasality occurs when the nasal cavities (the sinuses) resonate as a
result of the velum being lowered allowing air to escape out of the
nose. When there is an occlusion in the oral cavity then the resulting
sound is called a <strong>nasal murmur</strong>. The murmur is basically
a very low frequency formant, the <em>nasal formant</em>. But what about
place of articulation? Well, the acoustic features (namely F2 onset and
transition) that distinguish place in oral stops are likewise important
for nasal place perception. In the spectrograms below (/ma/-/am/,
/na/-/an/, /nga/-/ang/), for the NVs notice the initial nasal murmur,
then the transition into the vowel; and for the VNs notice the low
amplitude nasal murmurs.</p>
<p align="center">
<img src="images/ma-am.png" width="70%" height="70%"><img src="images/na-an.png" width="70%" height="70%"><img src="images/nga-ang.png" width="70%" height="70%">
</p>
<p>The F2 onset in NV sequences begins low for bilabials, high for
velars, and inbetween for alveolars.</p>
</div>
<div id="fricatives" class="section level2">
<h2>Fricatives</h2>
<p>Fricatives are characterized by high-frequency noise. The duration of
the noise cues the presence of a fricative (versus an affricate, which
has much shorter duration frication). The place of articulation is cued
by where in the spectrum the noise is centered. Sibilants (/s/, /ʃ/)
have steep high-frequency noise peaks, while non-sibilants have more
flatter spectra. /s/ has a higher centered peak (around 4kHz) than /ʃ/
and its voiced counterpart. The two dental fricatives, /f/ and /θ/ have
very similar spectra, and as a result sound very similar.</p>
</div>
<div id="affricates" class="section level2">
<h2>Affricates</h2>
<p>Affricates are essentially a stop which is released into a fricative.
The duration of the fricative portion is shorter than a true fricative,
but there is frication nonetheless. The stop portion is characterized by
“silence”, which is followed by a quick (~30ms) rise time for the
amplitude of the frication.</p>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
