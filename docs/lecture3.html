<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Sounds 1</title>

<script src="site_libs/header-attrs-2.23/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/paper.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.13.2/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link rel="shortcut icon" href="images/brain_tongue.jpg">

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>









<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">LING4320</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="article-assignments.html">Article assignments</a>
</li>
<li>
  <a href="lecture1.html">Lecture 1</a>
</li>
<li>
  <a href="lecture2.html">Lecture 2</a>
</li>
<li>
  <a href="lecture3.html">Lecture 3</a>
</li>
<li>
  <a href="lecture4.html">Lecture 4</a>
</li>
<li>
  <a href="lecture5.html">Lecture 5</a>
</li>
<li>
  <a href="lecture6.html">Lecture 6</a>
</li>
<li>
  <a href="lecture7.html">Lecture 7</a>
</li>
<li>
  <a href="lecture8.html">Lecture 8</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Sounds 1</h1>

</div>


<style type="text/css">
  body{
  font-size: 12pt;
}
</style>
<div id="from-sound-to-synapse" class="section level1">
<h1>From sound to synapse</h1>
<p>Sound is the psychological interpretation of a physical disturbance
of air molecules. This disturbance, caused by some incident (like
clapping hands, slamming doors, vibrating vocal folds), travels from the
source to the listeners ears much like a row of dominoes, but in this
case the dominoes are air molecules bumping into each other.</p>
<p>When the air around the listener’s ear drum is disturbed, it pushes
against the ear drum, which then physically moves bones (the smallest in
your body) called the ossicles. The movement of the ossicles causes
fluid in the cochlea (deep in your ear) to be set into motion. This
moving fluid then causes a membrane within the cochlea to rub against
another membrane that’s covered in hairs. These hairs essentially
“spark” and send an electrical signal through the auditory nerve to the
brain!</p>
<p align="center">
<img src="images/ossicles_animation.gif" width="50%" height="50%">
</p>
<p>This process is called <strong>transduction</strong> of sound from a
phsyical movement of air to the electrical signal sent along nerves to
the brain.</p>
<p>The book describes three steps of going from sound to meaning:</p>
<ol style="list-style-type: decimal">
<li>Acoustic signal to neuro-auditory representation
(<strong>neurogram</strong>)</li>
<li>Neurogram to neuro-phonoloigcal representation (<strong>phonological
sketch</strong>)</li>
<li>Phonological sketch to <strong>lexical item</strong> or meaning</li>
</ol>
<p>The neuro-auditory representation is essentially the parameters of
the spectrogram (remember what that is?!). They are a representation of
frequency, amplitude, and time. Let’s briefly review how we get from
moving our mouth and pushing air through the vocal folds to the
spectro-temporal output.</p>
</div>
<div id="low-level-speech-representation" class="section level1">
<h1>Low-level speech representation</h1>
<p>The acoustic “image” that represent using a spectrogram is the result
of two systems: a <strong>source</strong> system consisting of the vocal
folds, which are set into motion because of various physical phenomena
(Bernoulli effect). The result is a <em>complex periodic</em> sound
consisting of a fundamental frequency (pyschological “pitch”) and higher
harmonics (that are related to the fundamental). In the image below see
the “source function” as a line spectrum.</p>
<p>Above the vocal folds is the oral cavity which is the
<strong>filter</strong> system. The filter shapes the source energy in
specific ways depending on the shape of the mouth. The mouth
configuration either amplifies or dampens various parts of the source
spectrum. This results in formant structure, or areas of loud
frequencies.</p>
<p align="center">
<img src="images/transfer_fucntion_iu.png" width="60%%" height="60%">
</p>
<p><br />
</p>
<p>This source-filter interaction results in a complex spectro (energy
in frequency bands)-temporal (in time as speech unfolds). Imagine the
spectro-temporal representation of speech without any labels, this is
what your ear/cochlea/first stop in auditory pathway is receiving:</p>
<p align="center">
<img src="images/lang_spec.png" width="70%%" height="70%">
</p>
<p><br />
</p>
</div>
<div id="tonotopy-in-the-cochlea" class="section level1">
<h1>Tonotopy in the cochlea</h1>
<p>We know that the cochlea “resolves” the incoming speech signal by
performing Fourier analysis:</p>
<p align="center">
<img src="images/cochlea-tonotopy.png" width="50%" height="50%">
</p>
<p><br />
</p>
<p>The incoming complex speech waveform is “broken down” into component
sine waves:</p>
<p align="center">
<img src="images/fft.png" width="50%" height="50%">
</p>
<p><br />
</p>
<p>The resulting representation of in the cochlea is called a
<strong>cochleogram</strong> (like spectrogram).</p>
</div>
<div id="to-the-brain" class="section level1">
<h1>To the brain</h1>
<p>The signal is then sent to the brain via the auditory nerve and
arrives at the STG and specifically <strong>Heschl’s gyrus</strong> or
the <strong>primary auditory cortex</strong>. There is evidence that the
auditory cortex is itself <strong>tonotopic</strong> in organization.
[But why the redundancy?]</p>
<p><a
href="https://journals.physiology.org/doi/full/10.1152/jn.01125.2002">Talavage
et al. (2004)</a> did an experiment where subjects heard a <a
href="sounds/tone-sweep.wav">tone sweep</a> while in an MRI. The authors
looked for peaks in the BOLD signal in the auditory cortex. The peaks
moved as the frequency of the tone increased.</p>
<p>The firing of a neuron in response to a tone is called the neuron’s
<em>receptive field</em>. So we can say that the receptive fields of the
neurons in the auditory cortex are tuned to different frequencies. This
is the tonotopic organization of the primary auditory cortex.</p>
</div>
<div id="entrainment" class="section level1">
<h1>Entrainment</h1>
<p>The brain has to capture not only frequency information but time
information as well. The time information is basically the waveform of
the speech sound.</p>
<p align="center">
<img src="images/waveform.png" width="80%" height="80%">
</p>
<p><br />
</p>
<p>The temporal “envelope” is the shape of the time-varying amplitude
signal. In the waveform above, for the speech sample saying “language
and the brain”, the envelope is shown in red.</p>
<p>We will learn (in detail) from a paper by <a
href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0053398">Kubanek
et al. (2013)</a> that the brain tracks this temporal envelope rather
accurately in the auditory cortex as well language areas STG (superior
temporal gyrus) and Broca’s area (IFG, inferior frontal gyrus). This
<em>tracking</em> of the temporal signal is called
<strong>entrainment</strong>, or the synchronization of neuronal
activity to an external stimuli. Entrainment in the brain is found for
lots of different external stimuli such as speech, music, and even
tactile stimuli.</p>
<p>Entrainment is a more general phsyical concept that is evident when
small amounts of energy is transferred between oscillating bodies that
are initially out of phase, but soon “lock on” to a particular
frequency, as in this <a
href="https://www.youtube.com/watch?v=T58lGKREubo&amp;t=1s">famous
metronome experiment</a>.</p>
<div id="cocktail-party-effect" class="section level2">
<h2>Cocktail party effect</h2>
<p>Entrianment suggests that incoming speech is fully analyzed or
represented very early on in the speech decomposition stream in the
brain. Kubanek et al. show that the envelope is tracked by the auditory
cortex. The question then becomes, does our brain spend all of this
neuronal effort in tracking all speech that enters our ears?</p>
<p>No, our brain is selective in what it chooses to decompose or
represent for further linguistic analysis. The best example of this is
the <strong>cocktail party effect</strong>. This is a common phenomenon
whereby the speech signal is selectively attended to despite there being
lots of background speech noise. Imagine you’re at a party where lots of
people are talking. We have the ability to home in on a particular
conversation (we “attend” to it) and block out all of the other
conversations.There is an amazing <a
href="https://en.wikipedia.org/wiki/Cocktail_party_effect">wiki</a>
article about it.</p>
<p>It turns out that we can alter the entrainment of the incoming speech
signal, resulting in hearing what we want to hear. Ding and Simon (2013)
had subjects listen to an audio book mixed with speech-like noise while
in an MEG machine. The noise was adjusted so that the original speech
was understandable, but with effort. The MEG tracked the neural activity
and were able to match it with the speech envelope.</p>
</div>
</div>
<div id="neurograms" class="section level1">
<h1>Neurograms</h1>
<p>Now that we’ve shown how the brain tracks temporal information, we
have to ask what about frequency information that distinguishes phonemes
from one another. Barton et al. (2010) did a MRI experiment where
subjects heard tone sweeps as well as period sweeps, where noise in
speech bands (like formants) were turned off and on with specific
periods. It turns out that the BOLD signal responds to both in similar
areas of the auditory cortex. All of this to say, the brain represents
both frequency and temporal information in the auditory cortex. The
“map” of the response to these types of stimuli result in what’s called
a <strong>neurogram</strong> (like <em>spectrogram</em>)</p>
<div id="from-neurogram-to-phoneme" class="section level2">
<h2>From neurogram to phoneme</h2>
<p>The whole enterprise of generative phonology is centered on the idea
that speech sounds have abstract representations characterized along
parameters like voicing, manner, place of articulation, etc., the
“features” of the sound, allowing them to be distinguished from other
similar sounds. But is there any reality to this abstraction?</p>
<p>We will learn from the work of <a
href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4350233/">Mesgarani
et al. (2014)</a> that indeed, there is some neural basis for the old
descriptions of phonemes using features. Using electrodes implanted on
ST lobe and auditory cortex, these researchers found activation to
speech sounds according to their (broad) distinctive features, mostly
manner, showing that populations of neurons in the STG have
<strong>phonemic receptive fields</strong>.</p>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
